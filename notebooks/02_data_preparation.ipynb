{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05a7a622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n",
      "Data loaded.\n",
      "Parsing polylines...\n",
      "Original rows: 5000, Cleaned rows: 4921\n",
      "\n",
      "Sample of the final pre-processed data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.618643</td>\n",
       "      <td>41.141412</td>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>2013-07-01 00:00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.618499</td>\n",
       "      <td>41.141376</td>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>2013-07-01 00:01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.620326</td>\n",
       "      <td>41.142510</td>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>2013-07-01 00:01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.622153</td>\n",
       "      <td>41.143815</td>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>2013-07-01 00:01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.623953</td>\n",
       "      <td>41.144373</td>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>2013-07-01 00:01:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude   latitude              trip_id           timestamp\n",
       "0  -8.618643  41.141412  1372636858620000589 2013-07-01 00:00:58\n",
       "1  -8.618499  41.141376  1372636858620000589 2013-07-01 00:01:13\n",
       "2  -8.620326  41.142510  1372636858620000589 2013-07-01 00:01:28\n",
       "3  -8.622153  41.143815  1372636858620000589 2013-07-01 00:01:43\n",
       "4  -8.623953  41.144373  1372636858620000589 2013-07-01 00:01:58"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In notebooks/02_data_preparation.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load the raw data ---\n",
    "# We'll only load the first 5000 rows for this example to keep it fast.\n",
    "# For your final training, you might want to use more.\n",
    "print(\"Loading raw data...\")\n",
    "df_raw = pd.read_csv('../data/raw/train.csv', nrows=5000)\n",
    "print(\"Data loaded.\")\n",
    "\n",
    "# --- 2. Create a function to parse the POLYLINE string ---\n",
    "def parse_polyline(polyline_str):\n",
    "    \"\"\"\n",
    "    Converts the string representation of a polyline into a list of tuples.\n",
    "    Returns an empty list if the string is invalid or empty.\n",
    "    \"\"\"\n",
    "    # A trajectory needs at least two points to be useful\n",
    "    if not isinstance(polyline_str, str) or len(polyline_str) < 10:\n",
    "        return []\n",
    "    try:\n",
    "        # The json library is perfect for parsing this string format\n",
    "        return json.loads(polyline_str)\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "\n",
    "# --- 3. Apply the function and clean up the data ---\n",
    "print(\"Parsing polylines...\")\n",
    "df_raw['trajectory'] = df_raw['POLYLINE'].apply(parse_polyline)\n",
    "\n",
    "# Filter out any trips that had empty or invalid polylines\n",
    "df_clean = df_raw[df_raw['trajectory'].apply(len) > 1].copy()\n",
    "\n",
    "print(f\"Original rows: {len(df_raw)}, Cleaned rows: {len(df_clean)}\")\n",
    "\n",
    "# --- 4. Convert trajectories into a more useful format ---\n",
    "# We want a DataFrame where each row is a single GPS point.\n",
    "# This will make it easier to simulate anomalies.\n",
    "\n",
    "all_trajectories = []\n",
    "for index, row in df_clean.iterrows():\n",
    "    trip_id = row['TRIP_ID']\n",
    "    points = row['trajectory']\n",
    "    \n",
    "    # Create a DataFrame for this single trip\n",
    "    trip_df = pd.DataFrame(points, columns=['longitude', 'latitude'])\n",
    "    trip_df['trip_id'] = trip_id\n",
    "    \n",
    "    # Add a timestamp (taxis report every 15 seconds)\n",
    "    trip_df['timestamp'] = pd.to_datetime(row['TIMESTAMP'], unit='s') + pd.to_timedelta(np.arange(len(points)) * 15, unit='s')\n",
    "    \n",
    "    all_trajectories.append(trip_df)\n",
    "\n",
    "# Combine all the individual trip DataFrames into one big one\n",
    "df_full = pd.concat(all_trajectories, ignore_index=True)\n",
    "\n",
    "print(\"\\nSample of the final pre-processed data:\")\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa8bf838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly simulation functions are ready.\n"
     ]
    }
   ],
   "source": [
    "# In notebooks/02_data_preparation.ipynb\n",
    "\n",
    "def simulate_inactivity(traj_df: pd.DataFrame):\n",
    "    \"\"\"Simulates prolonged inactivity by duplicating a point.\"\"\"\n",
    "    if len(traj_df) < 20: # Need a long enough trip\n",
    "        return None\n",
    "    \n",
    "    # Pick a random point in the middle to stop at\n",
    "    stop_index = len(traj_df) // 2\n",
    "    \n",
    "    # 'Stop' for 10 timestamps (10 * 15s = 2.5 minutes)\n",
    "    for i in range(10):\n",
    "        traj_df.iloc[stop_index + i] = traj_df.iloc[stop_index]\n",
    "        \n",
    "    return traj_df\n",
    "\n",
    "def simulate_teleport(traj_df: pd.DataFrame):\n",
    "    \"\"\"Simulates a teleport by moving a single point far away.\"\"\"\n",
    "    if len(traj_df) < 10:\n",
    "        return None\n",
    "    \n",
    "    # --- FIX: Reset the index to work with .loc ---\n",
    "    traj_df = traj_df.reset_index(drop=True)\n",
    "    \n",
    "    point_to_change = len(traj_df) // 2\n",
    "    \n",
    "    # Add a large offset to create a huge jump\n",
    "    traj_df.loc[point_to_change, 'latitude'] += 0.5\n",
    "    traj_df.loc[point_to_change, 'longitude'] += 0.5\n",
    "    \n",
    "    return traj_df\n",
    "\n",
    "def simulate_deviation(traj_df: pd.DataFrame):\n",
    "    \"\"\"Simulates a route deviation by adding an offset to a segment.\"\"\"\n",
    "    if len(traj_df) < 20:\n",
    "        return None\n",
    "        \n",
    "    # --- FIX: Reset the index to work with .loc ---\n",
    "    traj_df = traj_df.reset_index(drop=True)\n",
    "        \n",
    "    start_index = len(traj_df) // 2\n",
    "    \n",
    "    # Deviate for 5 points\n",
    "    for i in range(5):\n",
    "        traj_df.loc[start_index + i, 'latitude'] += 0.005\n",
    "        traj_df.loc[start_index + i, 'longitude'] += 0.005\n",
    "        \n",
    "    return traj_df\n",
    "\n",
    "print(\"Anomaly simulation functions are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11dd113f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4920 trips to generate training data...\n",
      "  Processed 100/4920 trips...\n",
      "  Processed 200/4920 trips...\n",
      "  Processed 300/4920 trips...\n",
      "  Processed 400/4920 trips...\n",
      "  Processed 500/4920 trips...\n",
      "  Processed 600/4920 trips...\n",
      "  Processed 700/4920 trips...\n",
      "  Processed 800/4920 trips...\n",
      "  Processed 900/4920 trips...\n",
      "  Processed 1000/4920 trips...\n",
      "  Processed 1100/4920 trips...\n",
      "  Processed 1200/4920 trips...\n",
      "  Processed 1300/4920 trips...\n",
      "  Processed 1400/4920 trips...\n",
      "  Processed 1500/4920 trips...\n",
      "  Processed 1600/4920 trips...\n",
      "  Processed 1700/4920 trips...\n",
      "  Processed 1800/4920 trips...\n",
      "  Processed 1900/4920 trips...\n",
      "  Processed 2000/4920 trips...\n",
      "  Processed 2100/4920 trips...\n",
      "  Processed 2200/4920 trips...\n",
      "  Processed 2300/4920 trips...\n",
      "  Processed 2400/4920 trips...\n",
      "  Processed 2500/4920 trips...\n",
      "  Processed 2600/4920 trips...\n",
      "  Processed 2700/4920 trips...\n",
      "  Processed 2800/4920 trips...\n",
      "  Processed 2900/4920 trips...\n",
      "  Processed 3000/4920 trips...\n",
      "  Processed 3100/4920 trips...\n",
      "  Processed 3200/4920 trips...\n",
      "  Processed 3300/4920 trips...\n",
      "  Processed 3400/4920 trips...\n",
      "  Processed 3500/4920 trips...\n",
      "  Processed 3600/4920 trips...\n",
      "  Processed 3700/4920 trips...\n",
      "  Processed 3800/4920 trips...\n",
      "  Processed 3900/4920 trips...\n",
      "  Processed 4000/4920 trips...\n",
      "  Processed 4100/4920 trips...\n",
      "  Processed 4200/4920 trips...\n",
      "  Processed 4300/4920 trips...\n",
      "  Processed 4400/4920 trips...\n",
      "  Processed 4500/4920 trips...\n",
      "  Processed 4600/4920 trips...\n",
      "  Processed 4700/4920 trips...\n",
      "  Processed 4800/4920 trips...\n",
      "  Processed 4900/4920 trips...\n",
      "\n",
      "--- All Done! ---\n",
      "Shape of final X (features): (426340, 30, 4)\n",
      "Shape of final y (labels): (426340,)\n",
      "You are now ready to run the training script!\n"
     ]
    }
   ],
   "source": [
    "# In notebooks/02_data_preparation.ipynb\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Adds the main project folder to the path to find the 'app' module.\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Now, the import will work correctly\n",
    "from app.preprocessing import prepare_training_data\n",
    "\n",
    "# Get a list of unique trip IDs to iterate over\n",
    "unique_trip_ids = df_clean['TRIP_ID'].unique()\n",
    "\n",
    "all_X = []\n",
    "all_y = []\n",
    "\n",
    "print(f\"Processing {len(unique_trip_ids)} trips to generate training data...\")\n",
    "\n",
    "for i, trip_id in enumerate(unique_trip_ids):\n",
    "    # Get the original, normal trajectory\n",
    "    normal_traj = df_full[df_full['trip_id'] == trip_id].copy()\n",
    "    \n",
    "    # --- Process 4 versions for each trip ---\n",
    "    \n",
    "    # 1. Normal (Label 0)\n",
    "    X, y = prepare_training_data(normal_traj)\n",
    "    # --- FIX: Only append if the array is not empty ---\n",
    "    if X.shape[0] > 0:\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "\n",
    "    # 2. Inactivity (Label 1)\n",
    "    inactive_traj = simulate_inactivity(normal_traj.copy())\n",
    "    if inactive_traj is not None:\n",
    "        X, y = prepare_training_data(inactive_traj)\n",
    "        # --- FIX: Only append if the array is not empty ---\n",
    "        if X.shape[0] > 0:\n",
    "            all_X.append(X)\n",
    "            all_y.append(y)\n",
    "\n",
    "    # 3. Teleport (Label 2)\n",
    "    teleport_traj = simulate_teleport(normal_traj.copy())\n",
    "    if teleport_traj is not None:\n",
    "        X, y = prepare_training_data(teleport_traj)\n",
    "        # --- FIX: Only append if the array is not empty ---\n",
    "        if X.shape[0] > 0:\n",
    "            all_X.append(X)\n",
    "            all_y.append(y)\n",
    "        \n",
    "    # 4. Deviation (Label 3)\n",
    "    deviation_traj = simulate_deviation(normal_traj.copy())\n",
    "    if deviation_traj is not None:\n",
    "        X, y = prepare_training_data(deviation_traj)\n",
    "        # --- FIX: Only append if the array is not empty ---\n",
    "        if X.shape[0] > 0:\n",
    "            all_X.append(X)\n",
    "            all_y.append(y)\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"  Processed {i+1}/{len(unique_trip_ids)} trips...\")\n",
    "\n",
    "\n",
    "# --- Combine and Save ---\n",
    "final_X = np.concatenate(all_X, axis=0)\n",
    "final_y = np.concatenate(all_y, axis=0)\n",
    "\n",
    "# Make sure the processed data folder exists\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save the final arrays\n",
    "np.save('../data/processed/X.npy', final_X)\n",
    "np.save('../data/processed/y.npy', final_y)\n",
    "\n",
    "print(\"\\n--- All Done! ---\")\n",
    "print(f\"Shape of final X (features): {final_X.shape}\")\n",
    "print(f\"Shape of final y (labels): {final_y.shape}\")\n",
    "print(\"You are now ready to run the training script!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
