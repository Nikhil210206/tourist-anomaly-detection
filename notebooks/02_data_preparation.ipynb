{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05a7a622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n",
      "Data loaded.\n",
      "Parsing polylines...\n",
      "Original rows: 5000, Cleaned rows: 4921\n",
      "\n",
      "Sample of the final pre-processed data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.618643</td>\n",
       "      <td>41.141412</td>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>2013-07-01 00:00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.618499</td>\n",
       "      <td>41.141376</td>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>2013-07-01 00:01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.620326</td>\n",
       "      <td>41.142510</td>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>2013-07-01 00:01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.622153</td>\n",
       "      <td>41.143815</td>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>2013-07-01 00:01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.623953</td>\n",
       "      <td>41.144373</td>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>2013-07-01 00:01:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude   latitude              trip_id           timestamp\n",
       "0  -8.618643  41.141412  1372636858620000589 2013-07-01 00:00:58\n",
       "1  -8.618499  41.141376  1372636858620000589 2013-07-01 00:01:13\n",
       "2  -8.620326  41.142510  1372636858620000589 2013-07-01 00:01:28\n",
       "3  -8.622153  41.143815  1372636858620000589 2013-07-01 00:01:43\n",
       "4  -8.623953  41.144373  1372636858620000589 2013-07-01 00:01:58"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In notebooks/02_data_preparation.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load the raw data ---\n",
    "# We'll only load the first 5000 rows for this example to keep it fast.\n",
    "# For your final training, you might want to use more.\n",
    "print(\"Loading raw data...\")\n",
    "df_raw = pd.read_csv('../data/raw/train.csv', nrows=5000)\n",
    "print(\"Data loaded.\")\n",
    "\n",
    "# --- 2. Create a function to parse the POLYLINE string ---\n",
    "def parse_polyline(polyline_str):\n",
    "    \"\"\"\n",
    "    Converts the string representation of a polyline into a list of tuples.\n",
    "    Returns an empty list if the string is invalid or empty.\n",
    "    \"\"\"\n",
    "    # A trajectory needs at least two points to be useful\n",
    "    if not isinstance(polyline_str, str) or len(polyline_str) < 10:\n",
    "        return []\n",
    "    try:\n",
    "        # The json library is perfect for parsing this string format\n",
    "        return json.loads(polyline_str)\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "\n",
    "# --- 3. Apply the function and clean up the data ---\n",
    "print(\"Parsing polylines...\")\n",
    "df_raw['trajectory'] = df_raw['POLYLINE'].apply(parse_polyline)\n",
    "\n",
    "# Filter out any trips that had empty or invalid polylines\n",
    "df_clean = df_raw[df_raw['trajectory'].apply(len) > 1].copy()\n",
    "\n",
    "print(f\"Original rows: {len(df_raw)}, Cleaned rows: {len(df_clean)}\")\n",
    "\n",
    "# --- 4. Convert trajectories into a more useful format ---\n",
    "# We want a DataFrame where each row is a single GPS point.\n",
    "# This will make it easier to simulate anomalies.\n",
    "\n",
    "all_trajectories = []\n",
    "for index, row in df_clean.iterrows():\n",
    "    trip_id = row['TRIP_ID']\n",
    "    points = row['trajectory']\n",
    "    \n",
    "    # Create a DataFrame for this single trip\n",
    "    trip_df = pd.DataFrame(points, columns=['longitude', 'latitude'])\n",
    "    trip_df['trip_id'] = trip_id\n",
    "    \n",
    "    # Add a timestamp (taxis report every 15 seconds)\n",
    "    trip_df['timestamp'] = pd.to_datetime(row['TIMESTAMP'], unit='s') + pd.to_timedelta(np.arange(len(points)) * 15, unit='s')\n",
    "    \n",
    "    all_trajectories.append(trip_df)\n",
    "\n",
    "# Combine all the individual trip DataFrames into one big one\n",
    "df_full = pd.concat(all_trajectories, ignore_index=True)\n",
    "\n",
    "print(\"\\nSample of the final pre-processed data:\")\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa8bf838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly simulation functions are ready.\n"
     ]
    }
   ],
   "source": [
    "def simulate_inactivity(traj_df: pd.DataFrame):\n",
    "    \"\"\"Simulates prolonged inactivity by duplicating a point.\"\"\"\n",
    "    if len(traj_df) < 20: # Need a long enough trip\n",
    "        return None\n",
    "    \n",
    "    # Pick a random point in the middle to stop at\n",
    "    stop_index = len(traj_df) // 2\n",
    "    \n",
    "    # 'Stop' for 10 timestamps (10 * 15s = 2.5 minutes)\n",
    "    for i in range(10):\n",
    "        traj_df.iloc[stop_index + i] = traj_df.iloc[stop_index]\n",
    "        \n",
    "    return traj_df\n",
    "\n",
    "def simulate_teleport(traj_df: pd.DataFrame):\n",
    "    \"\"\"Simulates a teleport by moving a single point far away.\"\"\"\n",
    "    if len(traj_df) < 10:\n",
    "        return None\n",
    "    \n",
    "    point_to_change = len(traj_df) // 2\n",
    "    \n",
    "    # Add a large offset to create a huge jump\n",
    "    traj_df.loc[point_to_change, 'latitude'] += 0.5\n",
    "    traj_df.loc[point_to_change, 'longitude'] += 0.5\n",
    "    \n",
    "    return traj_df\n",
    "\n",
    "def simulate_deviation(traj_df: pd.DataFrame):\n",
    "    \"\"\"Simulates a route deviation by adding an offset to a segment.\"\"\"\n",
    "    if len(traj_df) < 20:\n",
    "        return None\n",
    "        \n",
    "    start_index = len(traj_df) // 2\n",
    "    \n",
    "    # Deviate for 5 points\n",
    "    for i in range(5):\n",
    "        traj_df.loc[start_index + i, 'latitude'] += 0.005\n",
    "        traj_df.loc[start_index + i, 'longitude'] += 0.005\n",
    "        \n",
    "    return traj_df\n",
    "\n",
    "print(\"Anomaly simulation functions are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11dd113f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'app'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import the function from your app folder that does the final conversion\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mapp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m prepare_training_data\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Get a list of unique trip IDs to iterate over\u001b[39;00m\n\u001b[32m      5\u001b[39m unique_trip_ids = df_clean[\u001b[33m'\u001b[39m\u001b[33mTRIP_ID\u001b[39m\u001b[33m'\u001b[39m].unique()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'app'"
     ]
    }
   ],
   "source": [
    "# Import the function from your app folder that does the final conversion\n",
    "from app.preprocessing import prepare_training_data\n",
    "\n",
    "# Get a list of unique trip IDs to iterate over\n",
    "unique_trip_ids = df_clean['TRIP_ID'].unique()\n",
    "\n",
    "all_X = []\n",
    "all_y = []\n",
    "\n",
    "print(f\"Processing {len(unique_trip_ids)} trips to generate training data...\")\n",
    "\n",
    "for i, trip_id in enumerate(unique_trip_ids):\n",
    "    # Get the original, normal trajectory\n",
    "    normal_traj = df_full[df_full['trip_id'] == trip_id].copy()\n",
    "    \n",
    "    # --- Process 4 versions for each trip ---\n",
    "    \n",
    "    # 1. Normal (Label 0)\n",
    "    X, y = prepare_training_data(normal_traj)\n",
    "    all_X.append(X)\n",
    "    all_y.append(y)\n",
    "\n",
    "    # 2. Inactivity (Label 1)\n",
    "    inactive_traj = simulate_inactivity(normal_traj.copy())\n",
    "    if inactive_traj is not None:\n",
    "        X, y = prepare_training_data(inactive_traj)\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "\n",
    "    # 3. Teleport (Label 2)\n",
    "    teleport_traj = simulate_teleport(normal_traj.copy())\n",
    "    if teleport_traj is not None:\n",
    "        X, y = prepare_training_data(teleport_traj)\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "        \n",
    "    # 4. Deviation (Label 3)\n",
    "    deviation_traj = simulate_deviation(normal_traj.copy())\n",
    "    if deviation_traj is not None:\n",
    "        X, y = prepare_training_data(deviation_traj)\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"  Processed {i+1}/{len(unique_trip_ids)} trips...\")\n",
    "\n",
    "\n",
    "# --- Combine and Save ---\n",
    "final_X = np.concatenate(all_X, axis=0)\n",
    "final_y = np.concatenate(all_y, axis=0)\n",
    "\n",
    "# Make sure the processed data folder exists\n",
    "import os\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save the final arrays\n",
    "np.save('../data/processed/X.npy', final_X)\n",
    "np.save('../data/processed/y.npy', final_y)\n",
    "\n",
    "print(\"\\n--- All Done! ---\")\n",
    "print(f\"Shape of final X (features): {final_X.shape}\")\n",
    "print(f\"Shape of final y (labels): {final_y.shape}\")\n",
    "print(\"You are now ready to run the training script!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
